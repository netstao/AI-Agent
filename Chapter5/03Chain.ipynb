{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最常用的Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMChain 最常用的链式\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5\", temprature=0)\n",
    "prompt_template = \"帮我给{product}想三个注册的域名？\"\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(temprature=prompt_template,verbose=True))\n",
    "\n",
    "chain({\"product\": \"apple\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 顺序链 SimpleSequentialChain\n",
    "- 将前一个LLM的输出作为下一个LLM的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 帮我给农业的公司起一个响亮容易记忆的名字?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m农耕丰收集团\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 用5个词来描述一下这个公司的名字:农耕丰收集团\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m农业、丰收、集团、耕种、农耕\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'农业、丰收、集团、耕种、农耕'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只支持固定链路\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain.chains  import LLMChain\n",
    "\n",
    "chat_model  = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# chain1\n",
    "first_prompt = ChatPromptTemplate.from_template(\"帮我给{product}的公司起一个响亮容易记忆的名字?\")\n",
    "\n",
    "chain_one = LLMChain(llm=chat_model, prompt=first_prompt,verbose=True)\n",
    "\n",
    "#chain2  \n",
    "second_prompt = ChatPromptTemplate.from_template(\"用5个词来描述一下这个公司的名字:{company_name}\")\n",
    "                  \n",
    "chain_two = LLMChain(llm=chat_model, prompt=second_prompt, verbose=True)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "\n",
    "\n",
    "overall_simple_chain.run(\"农业\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialChain 支持多个链路的顺序执行\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 把下面的内容翻译成中文：\n",
      "\n",
      "\n",
      "Both llm and chat_model are objects that represent configuration for a particular model. \n",
      "You can initialize them with parameters like temperature and others, and pass them around. \n",
      "The main difference between them is their input and output schemas. The LLM objects take string as input and output string. \n",
      "The ChatModel objects take a list of messages as input and output a message\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 用一句话总结下面的内容：\n",
      "\n",
      "llm和chat_model都是代表特定模型配置的对象。您可以使用参数（如温度等）对它们进行初始化，并将它们传递给其他地方。它们之间的主要区别在于它们的输入和输出模式。LLM对象以字符串作为输入和输出字符串。ChatModel对象以消息列表作为输入，并输出一条消息。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 请识别下面的内容的语言？\n",
      "\n",
      "llm和chat_model是代表特定模型配置的对象，具有不同的输入和输出模式。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 用这段内容是中文。语言评论下面的摘要：\n",
      "\n",
      "llm和chat_model是代表特定模型配置的对象，具有不同的输入和输出模式。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: 对下面评论内容写个代码样列：\n",
      "\n",
      "这段内容描述了llm和chat_model这两个对象代表了特定模型配置，它们具有不同的输入和输出模式。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': '\\nBoth llm and chat_model are objects that represent configuration for a particular model. \\nYou can initialize them with parameters like temperature and others, and pass them around. \\nThe main difference between them is their input and output schemas. The LLM objects take string as input and output string. \\nThe ChatModel objects take a list of messages as input and output a message\\n',\n",
       " 'Chinese_Rview': 'llm和chat_model都是代表特定模型配置的对象。您可以使用参数（如温度等）对它们进行初始化，并将它们传递给其他地方。它们之间的主要区别在于它们的输入和输出模式。LLM对象以字符串作为输入和输出字符串。ChatModel对象以消息列表作为输入，并输出一条消息。',\n",
       " 'Chinese_Summary': 'llm和chat_model是代表特定模型配置的对象，具有不同的输入和输出模式。',\n",
       " 'Language': '这段内容是中文。',\n",
       " 'Comment': '这段内容描述了llm和chat_model这两个对象代表了特定模型配置，它们具有不同的输入和输出模式。',\n",
       " 'Code': '```python\\nclass llm:\\n    def __init__(self, input_mode):\\n        self.input_mode = input_mode\\n\\nclass chat_model:\\n    def __init__(self, output_mode):\\n        self.output_mode = output_mode\\n\\n# 创建llm对象和chat_model对象\\nllm_obj = llm(\"input_mode1\")\\nchat_model_obj = chat_model(\"output_mode1\")\\n\\n# 输出llm对象和chat_model对象的输入和输出模式\\nprint(\"llm对象的输入模式为：\", llm_obj.input_mode)\\nprint(\"chat_model对象的输出模式为：\", chat_model_obj.output_mode)\\n```'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# SequentialChain 支持多个链路的顺序执行\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain.chains  import LLMChain\n",
    "\n",
    "chat_model  = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "#chain 1 任务：翻译成中文\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\"把下面的内容翻译成中文：\\n\\n{content}\")\n",
    "chain_one = LLMChain(llm=chat_model, prompt=first_prompt, verbose=True, output_key=\"Chinese_Rview\")\n",
    "\n",
    "#chain 2 任务：对翻译后的中文进行总结摘要， input\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用一句话总结下面的内容：\\n\\n{Chinese_Rview}\")\n",
    "chain_two = LLMChain(llm=chat_model, prompt=second_prompt, verbose=True, output_key=\"Chinese_Summary\")\n",
    "\n",
    "#chain 3 任务: 智能识别语言， input_key 是上一个chain的output_key\n",
    "third_prompt = ChatPromptTemplate.from_template(\"请识别下面的内容的语言？\\n\\n{Chinese_Summary}\")\n",
    "chain_three = LLMChain(llm=chat_model, prompt=third_prompt, verbose=True, output_key=\"Language\")\n",
    "\n",
    "#chain 4 任务: 针对摘要使用指定语言进行评论 input_key 是上一个chain的output_key\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"用{Language}语言评论下面的摘要：\\n\\n{Chinese_Summary}\")\n",
    "chain_four = LLMChain(llm=chat_model, prompt=fourth_prompt, verbose=True, output_key=\"Comment\")\n",
    "\n",
    "#chain 5 任务: 对评论内容写个代码样列\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"对下面评论内容写个代码样列：\\n\\n{Comment}\")\n",
    "chain_five = LLMChain(llm=chat_model, prompt=fourth_prompt, verbose=True, output_key=\"Code\")\n",
    "                     \n",
    "#overall 任务: 翻译成中文->对翻译后的中文进行总结摘要-》智能识别语言-> 针对摘要使用指定语言进行评论\n",
    "\n",
    "overall_sequential_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four,chain_five], verbose=True,\n",
    "    input_variables=[\"content\"],\n",
    "    output_variables=[\"Chinese_Rview\", \"Chinese_Summary\", \"Language\", \"Comment\", \"Code\"]\n",
    ")\n",
    "\n",
    "content_en = \"\"\"\n",
    "Both llm and chat_model are objects that represent configuration for a particular model. \n",
    "You can initialize them with parameters like temperature and others, and pass them around. \n",
    "The main difference between them is their input and output schemas. The LLM objects take string as input and output string. \n",
    "The ChatModel objects take a list of messages as input and output a message\n",
    "\"\"\"\n",
    "overall_sequential_chain(content_en)\n",
    "\n",
    "# 并行链 ParallelChain\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
