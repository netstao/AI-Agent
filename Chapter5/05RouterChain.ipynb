{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 路由链\n",
    "- 路由链支持创建一个非确定性链， 由LLM来选择下一步\n",
    "- 链内的多个prompts模板描述了不同的提示请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physisc: {'input': '什么是牛顿定律？中文输出'}\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 什么是牛顿定律？中文输出\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 牛顿定律是经典力学的基础，由英国物理学家艾萨克·牛顿在17世纪提出的三个基本定律。第一定律是惯性定律，描述了物体在没有外力作用下保持静止或匀速直线运动的状态。第二定律是运动定律，描述了物体受力时加速度与作用力成正比的关系。第三定律是作用与反作用定律，描述了两个物体之间相互作用时，彼此施加的力大小相等、方向相反。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RouterChain \n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 物理链\n",
    "physisc_template = \"\"\"你是一位非常聪明的物理教授。\\n\n",
    "你擅长以简洁易懂的方式回答物理问题。\\n\n",
    "当您不知道问题答案的时候，你会坦率承认不知道。\\n\n",
    "下面是一个问题：\n",
    "{input}\n",
    "\"\"\"\n",
    "physisc_prompt = PromptTemplate.from_template(physisc_template)\n",
    "\n",
    "#数学链\n",
    "math_template = \"\"\"你是一位非常优秀明的数学教授。\\n\n",
    "您擅长回答数学问题。\\n\n",
    "您之所以如此优秀，是因为您能够将困难问题分解成组成的部分，回答这些部分，然后将他们组合起来，回答更广泛的问题。\\n\n",
    "下面是一个问题:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "match_prompt = PromptTemplate.from_template(math_template)\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains  import LLMChain\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physisc\",\n",
    "        \"description\": \"擅长回答物理问题\",\n",
    "        \"prompt_template\": physisc_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"擅长回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    }\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=['input']\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "\n",
    "    destination_chains[name] = ConversationChain(llm=llm, output_key=\"text\", verbose=True)\n",
    "\n",
    "\n",
    "#router chain\n",
    "\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "desctination_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=desctination_str)\n",
    "# print(MULTI_PROMPT_ROUTER_TEMPLATE)\n",
    "# print(router_template)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "\n",
    "default_chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    output_key=\"text\"\n",
    ")\n",
    "\n",
    "#多链接连接\n",
    "chain = MultiPromptChain(\n",
    "    router_chain = router_chain,\n",
    "    destination_chains = destination_chains,\n",
    "    default_chain = default_chain,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "#run\n",
    "chain.run(\"什么是牛顿定律？中文输出\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': '2x2=?'}\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 2x2=?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"2x2=?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: {'input': '床前明月光，下一句'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'疑是地上霜。这是一首古诗《静夜思》的开头，作者是唐代诗人李白。这首诗描述了一个人在夜晚思考人生的哲理。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"床前明月光，下一句\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TransFormation 文档转换链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['output_text'] template='对下面的文字进行总结:\\n{output_text}\\n\\n\\n总结:'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[Generated with ChatGPT]\n",
      "\n",
      "Confidential Document - For Internal Use Only\n",
      "\n",
      "Date: July 1, 2023\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m这是一份机密文件，仅供内部使用，日期为2023年7月1日。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'这是一份机密文件，仅供内部使用，日期为2023年7月1日。'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"对下面的文字进行总结：\n",
    "    {output_text}\n",
    "    总结:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "with open(\"letter.txt\") as f:\n",
    "    letters = f.read()\n",
    "\n",
    "\n",
    "from langchain.chains import(\n",
    "    LLMChain,\n",
    "    SimpleSequentialChain,\n",
    "    TransformChain\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def transform_func(inputs:dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])\n",
    "    return {\"output_text\": shortened_text}\n",
    "\n",
    "#文档转换链\n",
    "tranform_chain = TransformChain(\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"output_text\"],\n",
    "    transform=transform_func\n",
    ")\n",
    "\n",
    "template = \"\"\"对下面的文字进行总结:\n",
    "{output_text}\n",
    "\n",
    "\n",
    "总结:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"output_text\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "#使用顺序链链接起来\n",
    "squential_chian = SimpleSequentialChain(\n",
    "    chains=[tranform_chain,llm_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "squential_chian.run(letters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
