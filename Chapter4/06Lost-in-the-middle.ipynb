{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lost in the middle : 长上下文精度问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openai.api2d.net\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"OPENAI_API_BASE\"))\n",
    "#使用openai的官方sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain,StuffDocumentsChain\n",
    "from langchain.document_transformers import (\n",
    "    LongContextReorder\n",
    ")\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import  Chroma\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    " \n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(embeddings)\n",
    "\n",
    "#使用huggingface托管的开源LLM来做嵌入，MiniLM-L6-v2是一个较小的模型，可以在上运行\n",
    "embedings = HuggingFaceBgeEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
    "\n",
    "text = [\n",
    "    \"篮球是一项伟大的运动。\",\n",
    "    \"带我飞往月球是我最喜欢的歌曲之一。\",\n",
    "    \"凯尔特人队是我最喜欢的球队。\",\n",
    "    \"这是一篇关于波士顿凯尔特人的文件。\",\n",
    "    \"我非常喜欢去看电影。\",\n",
    "    \"波士顿凯尔特人队以20分的优势赢得了比赛。\",\n",
    "    \"这只是一段随机的文字。\",\n",
    "    \"《艾尔登之环》是过去15年最好的游戏之一。\",\n",
    "    \"L.科内特是凯尔特人队最好的球员之一。\",\n",
    "    \"拉里.伯德是一位标志性的NBA球员。\"\n",
    "]\n",
    "retrieval = Chroma.from_texts(text,embedings).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "query = \"关于我的喜好都知道什么?\"\n",
    "\n",
    "#根据相关性返回文本块\n",
    "docs = retrieval.get_relevant_documents(query)\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对检索结果进行排序\n",
    "#问题相关性越低的内容块放在中间\n",
    "#问题相关性越高的内容块放在头尾\n",
    "\n",
    "reordering = LongContextReorder()\n",
    "reo_docs = reordering.transform_documents(docs)\n",
    "\n",
    "#头尾共有4个高相关性内容块\n",
    "reo_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "#检查这种方案的精度效果\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "#设置llm\n",
    "llm = OpenAI(api_key=api_key, api_base=api_base,model=\"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "#设置prompt模板\n",
    "docs_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],\n",
    "    template=\"{page_content}\",\n",
    ")\n",
    "stuff_prompt_override = \"\"\"Given this text extracts:\n",
    "----------------------------------\n",
    "{content}\n",
    "----------------------------------\n",
    "Please extract the most relevant information from the text.\n",
    "{query}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=stuff_prompt_override,\n",
    "    input_variables=[\"content\", \"query\"],\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "WorkChain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=docs_prompt,\n",
    "    document_variable_name=\"content\",\n",
    ")\n",
    "\n",
    "WorkChain.run(\n",
    "    input_documents=reo_docs,query=\"关于我的喜好都知道什么?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
