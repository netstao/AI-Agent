{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何加载使用tool\n",
    "- 加载预制tool的方法\n",
    "- 几种tool的使用方式\n",
    "langchain预制了大量的tools，基本这些工具能满足大部分需求，\n",
    "https://github.com/langchain-ai/langchain/tree/v0.0.352/docs/docs/integrations/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加预制工具的方法\n",
    "from langchain.agents import load_tools\n",
    "tool_names = [...]\n",
    "tools = load_tools(tool_names) #使用load方法\n",
    "#有些tool需要单独设置llm\n",
    "from langchain.agents import load_tools\n",
    "tool_names = [...]\n",
    "llm = ...\n",
    "tools = load_tools(tool_names, llm=llm) #在load的时候指定llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Hussein Obama II'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['简介：习近平，男，汉族，1953年6月生，陕西富平人，1969年1月参加工作，1974年1月加入中国共产党，清华大学人文社会学...', '大力弘扬艰苦奋斗、勤俭节约精神(深入学习贯彻习… 做好科技金融这篇大文章(人民要论) 始终坚持“两个毫不动摇”(人民要论) 观察·特稿 更多+ 【理响中国】深化对互联网的认识 加快建设网络强国 ...', '网民们称呼他为“习大大”。在习近平的老家陕西,“大大”是被用来称呼父亲的兄弟。 2月19日,习近平“时间去哪儿了”的官方漫画形象发布。港媒评论称,这可以与“小平您好”相媲美。 习近平在足球迷...', '习仲勋与儿子习正宁、习近平在一起。(右下) 年轻的模样 2014年,习近平与夫人彭丽媛在多个场合的亮相,展示了中国领导层家庭生活的侧面。坊间对他们的昵称,“习...', '习近平是这么说的,也是这么做的。他去庆丰包子铺和百姓一起吃包子,他在雾霾天去南锣鼓巷,不戴口罩与百姓同呼吸共命运,他在教师节去北师大看望师生,听到学生询...', '今年5月,塔斯马尼亚州的16个小学生用稚嫩的汉字给习大大写信。没想到,梦想成真,收到了回信,还请来了习大大彭阿姨。 他们是怎么做到的? 早上去,晚上走。18号一...', '对习近平总书记,民间早已悄然称之为“习大大”。这个称呼如今从国内流传到了海外,从民间流传到了官方。而“习大大”的称呼之所以如此盛行,原因有两个:一是总书...', '“无情未必真豪杰,怜子如何不丈夫?”从陕北“村官”到大国领袖,习近平曾数次落泪,为亲情、为友情、为英雄豪情……今天,有理君为您独家揭秘,习近平的泪水为谁而...', '网友Casper lee说:“习大大此行展现出了一名成熟政治家的风范,谈吐儒雅,直面问题,充满担当。” 网友Zeo说:“咱们的国家天天报道中国领导人强权、刻板,可是实际...', '原标题:“习大大”昵称叫响在中国红火在海外 图为:澳大利亚前总理陆克文 (六)澳大利亚:转型升级成绩斐然 “习近平主席带领中国政府制定了清晰的计划来应对各种...']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"engine\": \"baidu\",\n",
    "    \"gl\": \"cn\",\n",
    "    \"hl\": \"zh-cn\",\n",
    "}\n",
    "search = SerpAPIWrapper(params=params)\n",
    "search.run(\"习大大的的姓名?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Dall-E\n",
    "Dall-E是openai出品的文到图AI大模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"dalle-image-generator\"])\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "output = agent.run(\"Create an image of a halloween night at a haunted museum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eleven Labs Text2Speech\n",
    "- ElevenLabs 是非常优秀的TTS合成API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eleven_labs_text2speech'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.tools import ElevenLabsText2SpeechTool\n",
    "from langchain_community.tools import ElevenLabsText2SpeechTool\n",
    "\n",
    "text_to_speak = \"Hello! 你好! Hola! नमस्ते! Bonjour! こんにちは! مرحبا! 안녕하세요! Ciao! Cześć! Привіт! வணக்கம்!\"\n",
    "\n",
    "tts = ElevenLabsText2SpeechTool(\n",
    "    voice=\"Bella\",\n",
    "    text_to_speak=text_to_speak,\n",
    "    verbose=True\n",
    ")\n",
    "tts.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file = tts.run(text_to_speak)\n",
    "# tts.play(speech_file)\n",
    "tts.stream_speech(text_to_speak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts.play(speech_file)\n",
    "tts.stream_speech(text_to_speak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "tools = load_tools([\"eleven_labs_text2speech\"])\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = agent.run(\"Tell me a joke and read it out for me.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphQL\n",
    "一种api查询语言，类似sql，我们用它来查询奈飞的数据库，查找一下和星球大战相关的电影，API地址https://swapi-graphql.netlify.app/.netlify/functions/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.utilities import GraphQLAPIWrapper\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"graphql\"],\n",
    "    graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\",\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to query the GraphQL database to retrieve the titles of all Star Wars films in Chinese.\n",
      "Action: query_graphql\n",
      "Action Input: query { allFilms { films { title } } }\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"{\\n  \\\"allFilms\\\": {\\n    \\\"films\\\": [\\n      {\\n        \\\"title\\\": \\\"A New Hope\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Empire Strikes Back\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Return of the Jedi\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Phantom Menace\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Attack of the Clones\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Revenge of the Sith\\\"\\n      }\\n    ]\\n  }\\n}\"\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the titles of all Star Wars films in English.\n",
      "Action: query_graphql\n",
      "Action Input: query { allFilms { films { title } } }\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"{\\n  \\\"allFilms\\\": {\\n    \\\"films\\\": [\\n      {\\n        \\\"title\\\": \\\"A New Hope\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Empire Strikes Back\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Return of the Jedi\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"The Phantom Menace\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Attack of the Clones\\\"\\n      },\\n      {\\n        \\\"title\\\": \\\"Revenge of the Sith\\\"\\n      }\\n    ]\\n  }\\n}\"\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 所有星球大战电影的标题是：“新希望”，“帝国反击战”，“绝地归来”，“幽灵的威胁”，“克隆人的进攻”，“西斯的复仇”。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'所有星球大战电影的标题是：“新希望”，“帝国反击战”，“绝地归来”，“幽灵的威胁”，“克隆人的进攻”，“西斯的复仇”。'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphql_fields = \"\"\"allFilms {\n",
    "    films {\n",
    "      title\n",
    "      director\n",
    "      releaseDate\n",
    "      speciesConnection {\n",
    "        species {\n",
    "          name\n",
    "          classification\n",
    "          homeworld {\n",
    "            name\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"Search for the titles of all the stawars films stored in the graphql database that has this schema,and answer in chinese:\"\n",
    "\n",
    "\n",
    "agent.run(suffix + graphql_fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
