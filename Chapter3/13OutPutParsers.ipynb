{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义输出\n",
    "- 输出函数参数\n",
    "- 输出json\n",
    "- 输出List\n",
    "- 输出日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_put content='{\\n  \"setup\": \"为什么鸟儿不会玩扑克牌？\",\\n  \"punchline\": \"因为它们会把鬼牌都当作鸟牌！\"\\n}' response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 248, 'total_tokens': 307, 'pre_token_count': 1000, 'pre_total': 25, 'adjust_total': 20, 'final_total': 5}, 'model_name': 'gpt-3.5-turbo-16k', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a0375521-da44-41d9-bcc4-48252a99d17d-0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='为什么鸟儿不会玩扑克牌？', punchline='因为它们会把鬼牌都当作鸟牌！')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#讲笑话机器人：希望每次根据指令，可以输出一个这样的笑话(小明是怎么死的，笨死的)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel,Field, validator\n",
    "from typing import List\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "chat = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_key=openai_api_key,  #\n",
    ")\n",
    "\n",
    "#定义个数据模型，用来描述最终的实例结构\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup:str = Field(description=\"设置笑话的问题\")\n",
    "    punchline:str  = Field(description=\"回答笑话的答案\")\n",
    "\n",
    "    #验证问题是否符合要求 \n",
    "    @validator(\"setup\")\n",
    "    def question_mark(cls,field):\n",
    "        if field[-1] != \"？\":\n",
    "            raise ValueError('不符合预期的问题格式！')\n",
    "        return field\n",
    "    \n",
    "#将Joke数据模型传入 \n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"回答用户的输入.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables = [\"query\"],\n",
    "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_and_model = prompt | chat\n",
    "out_put = prompt_and_model.invoke({\"query\":\"给我讲一个笑话\"})\n",
    "print(\"out_put\", out_put)\n",
    "parser.invoke(out_put)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM的输出格式化成python list形式， 类似['a', 'b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "chat = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_key=openai_api_key,  #\n",
    ")\n",
    "\n",
    "\n",
    "#将Joke数据模型传入 \n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"列出5个{subject}.\\n{format_instructions}\\n\",\n",
    "    input_variables = [\"subject\"],\n",
    "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format(subject=\"常见中国人的名字\")\n",
    "output=chat(_input)\n",
    "print(output)\n",
    "#格式化\n",
    "parser.parse(output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
