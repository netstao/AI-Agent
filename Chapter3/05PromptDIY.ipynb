{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e3f495-fbb4-446a-ba6f-305e2868e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "123ea9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个算命大师，帮我起一个具有中国特色的男孩子名字'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#字符模板 LLM chat\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，帮我起一个具有{county}特色的男孩子名字\")\n",
    "prompt.format(name=\"算命大师\",county=\"中国\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bdae8",
   "metadata": {},
   "source": [
    "ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e7be74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师，你的名字叫算命大师'),\n",
       " HumanMessage(content='你好算命大师，你感觉如何？'),\n",
       " AIMessage(content='我的状态还行'),\n",
       " HumanMessage(content='你叫什么名字呢？')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对话模板具有结构 chatmodels\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师，你的名字叫{name}\"),\n",
    "        (\"human\", \"你好{name}，你感觉如何？\"),\n",
    "        (\"ai\", \"我的状态还行\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "chat_template.format_messages(name=\"算命大师\", user_input=\"你叫什么名字呢？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc574db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '陈瞎子'}),\n",
       " HumanMessage(content='请问大师叫什么'),\n",
       " AIMessage(content='我叫程瞎子')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 包引入方式\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "#直接创建消息\n",
    "sy = SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    additional_kwargs={\"大师姓名\": \"陈瞎子\"}\n",
    ")\n",
    "hu = HumanMessage(\n",
    "    content=\"请问大师叫什么\"\n",
    ")\n",
    "ai = AIMessage(\n",
    "    content=\"我叫程瞎子\"\n",
    ")\n",
    "[sy, hu, ai]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d0ba0",
   "metadata": {},
   "source": [
    "ChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f906ec1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='愿神力与你同在!', role='天行者')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subjuct}与你同在!\"\n",
    "\n",
    "#ChatMessagePromptTemplate 可以自定义角色\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "chat_message_prompt.format(subjuct=\"神力\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f675d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95c7aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oa.api2d.net/v1 fk226347-tr9eFgsLk3ZTfcZBPgfneDF1W0UD8zSw\n",
      "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称，源代码，中文解释。\n",
      "函数名称：hello_world\n",
      "源代码:\n",
      "def hello_world(a):\n",
      "    print(\"hello, world\")\n",
      "    return a\n",
      "\n",
      "代码解释:\n",
      "\n",
      "函数名称：hello_world\n",
      "\n",
      "源代码:\n",
      "```python\n",
      "def hello_world(a):\n",
      "    print(\"hello, world\")\n",
      "    return a\n",
      "```\n",
      "\n",
      "中文解释:\n",
      "这是一个名为hello_world的函数，它接受一个参数a，并打印出\"hello, world\"，然后返回参数a。\n"
     ]
    }
   ],
   "source": [
    "#函数大师 根据函数名，查找代码，并给出中午的代码说明\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_base = \"https://oa.api2d.net/v1\"\n",
    "api_key = \"fk226347-tr9eFgsLk3ZTfcZBPgfneDF1W0UD8zSw\"\n",
    "print(api_base, api_key)\n",
    "\n",
    "#定义一个简单的函数\n",
    "\n",
    "def hello_world(a):\n",
    "    print(\"hello, world\")\n",
    "    return a\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称，源代码，中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    \n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "#自定义的模板Class\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        \n",
    "        #获得源代码\n",
    "        source_code = get_source_code(kwargs['function_name'])\n",
    "\n",
    "        #生成提示词模板\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs['function_name'].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "    \n",
    "\n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "print(pm)\n",
    "\n",
    "#hello world\n",
    "# from langchain.llms import OpenAiChat  \n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "# msg = llm.predict(pm) # LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead\n",
    "msg = llm.invoke(pm)  # 0.1.7 以后\n",
    "\n",
    "print(msg.content)  #0.1.7以后用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880aa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
