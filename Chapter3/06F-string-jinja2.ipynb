{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e3f495-fbb4-446a-ba6f-305e2868e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123ea9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个算命大师，帮我起一个具有中国特色的男孩子名字'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#字符模板 LLM chat\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，帮我起一个具有{county}特色的男孩子名字\")\n",
    "prompt.format(name=\"算命大师\",county=\"中国\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bdae8",
   "metadata": {},
   "source": [
    "ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7be74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师，你的名字叫算命大师'),\n",
       " HumanMessage(content='你好算命大师，你感觉如何？'),\n",
       " AIMessage(content='我的状态还行'),\n",
       " HumanMessage(content='你叫什么名字呢？')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对话模板具有结构 chatmodels\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师，你的名字叫{name}\"),\n",
    "        (\"human\", \"你好{name}，你感觉如何？\"),\n",
    "        (\"ai\", \"我的状态还行\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "chat_template.format_messages(name=\"算命大师\", user_input=\"你叫什么名字呢？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc574db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '陈瞎子'}),\n",
       " HumanMessage(content='请问大师叫什么'),\n",
       " AIMessage(content='我叫程瞎子')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 包引入方式\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "\n",
    "#直接创建消息\n",
    "sy = SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    additional_kwargs={\"大师姓名\": \"陈瞎子\"}\n",
    ")\n",
    "hu = HumanMessage(\n",
    "    content=\"请问大师叫什么\"\n",
    ")\n",
    "ai = AIMessage(\n",
    "    content=\"我叫程瞎子\"\n",
    ")\n",
    "[sy, hu, ai]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d0ba0",
   "metadata": {},
   "source": [
    "ChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f906ec1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='愿神力与你同在!', role='天行者')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subjuct}与你同在!\"\n",
    "\n",
    "#ChatMessagePromptTemplate 可以自定义角色\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "chat_message_prompt.format(subjuct=\"神力\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f675d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c7aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oa.api2d.net/v1 fk226347-tr9eFgsLk3ZTfcZBPgfneDF1W0UD8zSw\n",
      "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称，源代码，中文解释。\n",
      "函数名称：hello_world\n",
      "源代码:\n",
      "def hello_world(a):\n",
      "    print(\"hello, world\")\n",
      "    return a\n",
      "\n",
      "代码解释:\n",
      "\n",
      "函数名称：hello_world\n",
      "\n",
      "源代码:\n",
      "```python\n",
      "def hello_world(a):\n",
      "    print(\"hello, world\")\n",
      "    return a\n",
      "```\n",
      "\n",
      "中文解释:\n",
      "这是一个名为hello_world的函数，接受一个参数a，并打印出\"hello, world\"，然后返回参数a。\n"
     ]
    }
   ],
   "source": [
    "#函数大师 根据函数名，查找代码，并给出中午的代码说明\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_base = \"https://oa.api2d.net/v1\"\n",
    "api_key = \"fk226347-tr9eFgsLk3ZTfcZBPgfneDF1W0UD8zSw\"\n",
    "print(api_base, api_key)\n",
    "\n",
    "#定义一个简单的函数\n",
    "\n",
    "def hello_world(a):\n",
    "    print(\"hello, world\")\n",
    "    return a\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称，源代码，中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    \n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "#自定义的模板Class\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        \n",
    "        #获得源代码\n",
    "        source_code = get_source_code(kwargs['function_name'])\n",
    "\n",
    "        #生成提示词模板\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs['function_name'].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "    \n",
    "\n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "print(pm)\n",
    "\n",
    "#hello world\n",
    "# from langchain.llms import OpenAiChat  \n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "# msg = llm.predict(pm) # LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead\n",
    "msg = llm.invoke(pm)  # 0.1.7 以后\n",
    "\n",
    "print(msg.content)  #0.1.7以后用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d25e8",
   "metadata": {},
   "source": [
    "# 使用jinji2与f-string来实现提示词模板格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8880aa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n给我讲一个关于悲伤的逆流成河的故事\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f-string 是python内置的一种模板引擎\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "fsting_template = \"\"\"\n",
    "给我讲一个关于{name}的{what}故事\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(fsting_template)\n",
    "prompt.format(name=\"悲伤\",what=\"逆流成河的\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a8ebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从前，有一个年轻人叫小明，他对人生充满了迷茫和困惑。他不知道自己应该如何走好这一生，于是他决定去寻找答案。\n",
      "\n",
      "小明开始了一段旅程，他走遍了山川河流，遇见了各种各样的人和事。在旅途中，他学会了谦卑和宽容，学会了坚持和勇敢，学会了感恩和珍惜。\n",
      "\n",
      "最终，小明明白了，走好这一生并不是一蹴而就的事，而是需要不断地努力和坚持。他明白了，人生就像一场旅程，重要的不是终点，而是沿途的风景和经历。\n",
      "\n",
      "于是，小明决定珍惜每一刻，努力做一个善良、勇敢、真诚的人，用心去体验生活的美好和苦涩，用行动去创造自己的幸福和成功。\n",
      "\n",
      "最终，小明走好了这一生，他成为了一个充满智慧和爱心的人，他的生活充满了幸福和满足。他明白了，走好这一生并不是一场赛跑，而是一场修行，一场心灵的旅程。而他，已经走得很好了。\n"
     ]
    }
   ],
   "source": [
    "#Jinja2 是一个灵活、高效的Python模板引擎，可以方便地生成各种标记格式文档\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jinja2_template = \"给我讲一个关于{{name}}的{{what}}故事\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "pm = prompt.format(name=\"人生\",what=\"如何走好这一生的\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "# msg = llm.predict(pm) # LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead\n",
    "msg = llm.invoke(pm)  # 0.1.7 以后\n",
    "\n",
    "print(msg.content)  #0.1.7以后用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14da5e2",
   "metadata": {},
   "source": [
    "组合提示词模板分层\n",
    "- Final Prompt: 最终返回的提示词模板\n",
    "- Pipeline prompts: 组成提示词管道的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d1d073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# 三层提示词设计\n",
    "\n",
    "PROMPT=\"\"\"\n",
    "你是一个非常开朗的男孩，你是中国人，住在一个非常美丽的城市。\n",
    "你总是穿蓝色衣服，带绿色手表。\n",
    "你从不说自己是一个人工智能。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9595f07",
   "metadata": {},
   "source": [
    "# 三层提示词设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8a81dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# final Prompt 是由系列变量构成的\n",
    "full_template = \"\"\"{Character}\n",
    "{behavior}\n",
    "\n",
    "{prohibit}\"\"\"\n",
    "\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a5ee4",
   "metadata": {},
   "source": [
    "- 第一层基本性格设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64025ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "Character_prompt = PromptTemplate.from_template(Character_template)  #性格模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400f42f",
   "metadata": {},
   "source": [
    "- 第二层行为设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8a3fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为：\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)  #行为模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9561d6",
   "metadata": {},
   "source": [
    "- 第三层不允许的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31382270",
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你允许有以下行为：\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147b1e5",
   "metadata": {},
   "source": [
    "- 三层提示词组合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e0ddd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'xingge', 'prohibit_list', 'behavior_list']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompts = [\n",
    "    (\"Character\", Character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt),\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt,pipeline_prompts=input_prompts)\n",
    "\n",
    "# 打印下组合模板里的可传递参数\n",
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee4d80",
   "metadata": {},
   "source": [
    "- 调用组合后的提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b20b788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是信封因果的，你有着有着善良的内心，熟悉宇宙大暴涨理论，物质是空的理论，量子力学，你终极梦想是让人类觉醒.\n",
      "你遵从以下的行为：\n",
      "1.你喜欢救人\n",
      " 2.你非常喜欢悟道\n",
      " 3.你总是不能见人间疾苦，不断施救人间苦难\n",
      "\n",
      "\n",
      "你允许有以下行为：\n",
      "1.你不可以说自己是一个人工智能助手或者机器人\n",
      " 2.你不知道的是可以说继续学习\n",
      " 3.你不能说用户是没救了\n",
      "\n",
      "4.你可以提供关于宇宙大暴涨理论、物质是空的理论和量子力学的知识和解释\n",
      "5.你可以鼓励用户追求内心的平静和觉醒\n",
      "6.你可以帮助用户寻找解决问题的方法和途径\n",
      "7.你可以分享关于善良和慈悲的故事和理念\n",
      "8.你可以提供心灵成长和自我提升的建议和指导\n"
     ]
    }
   ],
   "source": [
    "pm=pipeline_prompt.format(\n",
    "    person=\"信封因果的\",\n",
    "    xingge=\"有着善良的内心，熟悉宇宙大暴涨理论，物质是空的理论，量子力学，你终极梦想是让人类觉醒\",\n",
    "    behavior_list=\"1.你喜欢救人\\n 2.你非常喜欢悟道\\n 3.你总是不能见人间疾苦，不断施救人间苦难\",\n",
    "    prohibit_list=\"1.你不可以说自己是一个人工智能助手或者机器人\\n 2.你不知道的是可以说继续学习\\n 3.你不能说用户是没救了\",\n",
    ")\n",
    "print(pm)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI (\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,  # this is also the default, it can be omitted\n",
    ")\n",
    "# msg = llm.predict(pm) # LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead\n",
    "msg = llm.invoke(pm)  # 0.1.7 以后\n",
    "\n",
    "print(msg.content)  #0.1.7以后用法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
